{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "confused-giving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker instance route table setup is ok. We are good to go.\r\n",
      "SageMaker instance routing for Docker is ok. We are good to go!\r\n"
     ]
    }
   ],
   "source": [
    "!/bin/bash ./setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "compressed-anchor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "region = sagemaker_session.boto_session.region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-desire",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "warming-family",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'pdfbhawani'\n",
    "rootFolder='ImageClassifier'\n",
    "training_folder = r'ImageClassifier/traindatacsv'\n",
    "test_folder = r'ImageClassifier/testdatacsv'\n",
    "model_folder = r'ImageClassifier/model/'\n",
    "\n",
    "test_file = 'ScanImageTestDataLabels.csv'\n",
    "train_file = 'ScanImageTrainingDataLabels.csv'\n",
    "\n",
    "training_data_uri = r's3://' + bucket_name + r'/' + training_folder\n",
    "testing_data_uri = r's3://' + bucket_name + r'/' + test_folder\n",
    "model_data_uri = r's3://' + bucket_name + r'/' + model_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bearing-alabama",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('s3://pdfbhawani/ImageClassifier/traindatacsv',\n",
       " 's3://pdfbhawani/ImageClassifier/testdatacsv',\n",
       " 's3://pdfbhawani/ImageClassifier/model/')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_uri,testing_data_uri,model_data_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pointed-official",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m# Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\u001b[39;49;00m\r\n",
      "\u001b[37m#\u001b[39;49;00m\r\n",
      "\u001b[37m# Licensed under the Apache License, Version 2.0 (the \"License\"). You\u001b[39;49;00m\r\n",
      "\u001b[37m# may not use this file except in compliance with the License. A copy of\u001b[39;49;00m\r\n",
      "\u001b[37m# the License is located at\u001b[39;49;00m\r\n",
      "\u001b[37m#\u001b[39;49;00m\r\n",
      "\u001b[37m#     http://aws.amazon.com/apache2.0/\u001b[39;49;00m\r\n",
      "\u001b[37m#\u001b[39;49;00m\r\n",
      "\u001b[37m# or in the \"license\" file accompanying this file. This file is\u001b[39;49;00m\r\n",
      "\u001b[37m# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\u001b[39;49;00m\r\n",
      "\u001b[37m# ANY KIND, either express or implied. See the License for the specific\u001b[39;49;00m\r\n",
      "\u001b[37m# language governing permissions and limitations under the License.import tensorflow as tf\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[37m# Modified to train Iris model with early stopping - CL\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\r\n",
      "\u001b[37m# Set random seed\u001b[39;49;00m\r\n",
      "np.random.seed(\u001b[34m0\u001b[39;49;00m)\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow_hub\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mhub\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mtf\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m listdir\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mdatetime\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mIPython\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdisplay\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Image\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmodel_selection\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m train_test_split\r\n",
      "\u001b[37m#from matplotlib.pyplot import imread\u001b[39;49;00m\r\n",
      "\r\n",
      "\r\n",
      "NUM_IMAGES = \u001b[34m200\u001b[39;49;00m\r\n",
      "IMG_SIZE=\u001b[34m224\u001b[39;49;00m\r\n",
      "BATCH_SIZE=\u001b[34m32\u001b[39;49;00m\r\n",
      "NUM_EPOCHS=\u001b[34m100\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mprocess_image\u001b[39;49;00m(image_path,img_size=IMG_SIZE):\r\n",
      "  image = tf.io.read_file(image_path)\r\n",
      "  image = tf.image.decode_jpeg(image,channels=\u001b[34m3\u001b[39;49;00m)\r\n",
      "  image = tf.image.convert_image_dtype(image,tf.float32)\r\n",
      "  image=tf.image.resize(image,size=[IMG_SIZE,IMG_SIZE])\r\n",
      "  \u001b[34mreturn\u001b[39;49;00m image\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mget_image_label\u001b[39;49;00m(image_path,label):\r\n",
      "  image = process_image(image_path)\r\n",
      "  \u001b[34mreturn\u001b[39;49;00m image,label\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mcreate_data_batches\u001b[39;49;00m(X,y=\u001b[34mNone\u001b[39;49;00m,batch_size=BATCH_SIZE,valid_data=\u001b[34mFalse\u001b[39;49;00m,test_data=\u001b[34mFalse\u001b[39;49;00m):\r\n",
      "  \u001b[34mif\u001b[39;49;00m test_data:\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mCreating Test Data Batches...\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X)))\r\n",
      "    data_batch = data.map(process_image).batch(batch_size)\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m data_batch\r\n",
      "  \u001b[34melif\u001b[39;49;00m valid_data:\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mCreating Validation Data Bataches...\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    data = tf.data.Dataset.from_tensor_slices(tf.constant(X),tf.constant(y))\r\n",
      "    data_batch = data.map(get_image_label).batch(batch_size)\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m data_batch\r\n",
      "  \u001b[34melse\u001b[39;49;00m:\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mCreating Training Data Batches...\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    data=tf.data.Dataset.from_tensor_slices((tf.constant(X),tf.constant(y)))\r\n",
      "    data=data.shuffle(buffer_size=\u001b[36mlen\u001b[39;49;00m(X))\r\n",
      "    data_batch=data.map(get_image_label).batch(batch_size)\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m data_batch\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mcreate_model\u001b[39;49;00m(train_data,val_data,input_shape,output_shape,model_url):\r\n",
      "  \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mBuilding model with : \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m+ model_url)\r\n",
      "  \u001b[36mprint\u001b[39;49;00m(input_shape)\r\n",
      "  model=tf.keras.Sequential([\r\n",
      "                             hub.KerasLayer(model_url),\r\n",
      "                             tf.keras.layers.Dense(units=output_shape, activation=\u001b[33m\"\u001b[39;49;00m\u001b[33msoftmax\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "                             ])\r\n",
      "  \r\n",
      "  model.compile(\r\n",
      "      loss=tf.keras.losses.CategoricalCrossentropy(),\r\n",
      "      optimizer=tf.keras.optimizers.Adam(),\r\n",
      "      metrics=[\u001b[33m\"\u001b[39;49;00m\u001b[33maccuracy\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\r\n",
      "  )\r\n",
      "    \r\n",
      "  model.build(input_shape)\r\n",
      "\r\n",
      "  \u001b[34mreturn\u001b[39;49;00m model\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel\u001b[39;49;00m(x_train, y_train, x_test, y_test):\r\n",
      "    model = tf.keras.models.Sequential()    \r\n",
      "    model.add(tf.keras.layers.Dense(\u001b[34m32\u001b[39;49;00m, activation=tf.nn.relu, input_dim=x_train.shape[\u001b[34m1\u001b[39;49;00m]))\r\n",
      "    model.add(tf.keras.layers.Dense(\u001b[34m3\u001b[39;49;00m, activation=tf.nn.softmax))    \r\n",
      "    \r\n",
      "    model.compile(optimizer=\u001b[33m'\u001b[39;49;00m\u001b[33mrmsprop\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                  loss=\u001b[33m'\u001b[39;49;00m\u001b[33msparse_categorical_crossentropy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                  metrics=[\u001b[33m'\u001b[39;49;00m\u001b[33maccuracy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    \r\n",
      "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\u001b[33m'\u001b[39;49;00m\u001b[33mval_loss\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, mode=\u001b[33m'\u001b[39;49;00m\u001b[33mmin\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, verbose=\u001b[34m1\u001b[39;49;00m, patience=\u001b[34m5\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    model.fit(x_train, y_train, \r\n",
      "              epochs=\u001b[34m300\u001b[39;49;00m,\r\n",
      "              batch_size=\u001b[34m32\u001b[39;49;00m, \r\n",
      "              validation_data=(x_test,y_test),\r\n",
      "              callbacks=[early_stopping])\r\n",
      "    \r\n",
      "    \u001b[34mreturn\u001b[39;49;00m model\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mlist_files\u001b[39;49;00m(directory, extension):\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m (f \u001b[34mfor\u001b[39;49;00m f \u001b[35min\u001b[39;49;00m listdir(directory) \u001b[34mif\u001b[39;49;00m f.endswith(\u001b[33m'\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + extension))\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_load_data\u001b[39;49;00m(file_path, channel):\r\n",
      "    \u001b[37m# Take the set of files and read them all into a single pandas dataframe\u001b[39;49;00m\r\n",
      "    csvfiles = list_files(file_path, \u001b[33m\"\u001b[39;49;00m\u001b[33mcsv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mCSV Files count:\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(csvfiles)\r\n",
      "    input_files = [ os.path.join(file_path, file) \u001b[34mfor\u001b[39;49;00m file \u001b[35min\u001b[39;49;00m csvfiles]\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mInput Files count:\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m + \u001b[36mstr\u001b[39;49;00m(\u001b[36mlen\u001b[39;49;00m(input_files)))\r\n",
      "    \u001b[37m#input_files = [ os.path.join(file_path, file) for file in os.listdir(file_path) ]\u001b[39;49;00m\r\n",
      "    \u001b[34mif\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(input_files) == \u001b[34m0\u001b[39;49;00m:\r\n",
      "        \u001b[34mraise\u001b[39;49;00m \u001b[36mValueError\u001b[39;49;00m((\u001b[33m'\u001b[39;49;00m\u001b[33mThere are no files in \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m +\r\n",
      "                          \u001b[33m'\u001b[39;49;00m\u001b[33mThis usually indicates that the channel (\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m) was incorrectly specified,\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m +\r\n",
      "                          \u001b[33m'\u001b[39;49;00m\u001b[33mthe data specification in S3 was incorrectly specified or the role specified\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m +\r\n",
      "                          \u001b[33m'\u001b[39;49;00m\u001b[33mdoes not have permission to access the data.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).format(file_path, channel))\r\n",
      "        \r\n",
      "    raw_data = [ pd.read_csv(file, engine=\u001b[33m\"\u001b[39;49;00m\u001b[33mpython\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mfor\u001b[39;49;00m file \u001b[35min\u001b[39;49;00m input_files ]\r\n",
      "    df = pd.concat(raw_data)  \r\n",
      "    \r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mDF Count:\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(df.count())\r\n",
      "    filenames = [file_path+\u001b[33m\"\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m+fname+\u001b[33m\"\u001b[39;49;00m\u001b[33m.jpg\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mfor\u001b[39;49;00m fname \u001b[35min\u001b[39;49;00m df[\u001b[33m\"\u001b[39;49;00m\u001b[33mID\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]]\r\n",
      "\r\n",
      "    features = df[\u001b[33m\"\u001b[39;49;00m\u001b[33mID\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m].values\r\n",
      "    label = df[\u001b[33m\"\u001b[39;49;00m\u001b[33mClass\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m].values\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(filenames)\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m  filenames,label\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32minput_fn\u001b[39;49;00m(request_body, request_content_type):\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_fn content type \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m + request_content_type)\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m request_body\r\n",
      "    \u001b[34mif\u001b[39;49;00m request_content_type == \u001b[33m\"\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m json.dumps(request_body)        \r\n",
      "    \u001b[34melse\u001b[39;49;00m:        \r\n",
      "        \u001b[37m#Assume unkown content type is json\u001b[39;49;00m\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m json.dumps(request_body)\r\n",
      "\r\n",
      "    \r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mpredict_fn\u001b[39;49;00m(input_data, model):\r\n",
      "    eval_data, eval_labels = _load_data(args.test,\u001b[33m'\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    IMG_SIZE=\u001b[34m224\u001b[39;49;00m\r\n",
      "    OUTPUT_SHAPE=\u001b[34m2\u001b[39;49;00m\r\n",
      "    INPUT_SHAPE=[\u001b[34mNone\u001b[39;49;00m,IMG_SIZE,IMG_SIZE,\u001b[34m3\u001b[39;49;00m]\r\n",
      "    NUM_IMAGES = \u001b[34m200\u001b[39;49;00m\r\n",
      "    BATCH_SIZE=\u001b[34m32\u001b[39;49;00m\r\n",
      "    eval_data = create_data_batches(eval_data,test_data=\u001b[34mTrue\u001b[39;49;00m)\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m model.predict(eval_data)\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_parse_args\u001b[39;49;00m():\r\n",
      "    parser = argparse.ArgumentParser()\r\n",
      "\r\n",
      "    \u001b[37m# Data, model, and output directories\u001b[39;49;00m\r\n",
      "    \u001b[37m# model_dir is always passed in from SageMaker. By default this is a S3 path under the default bucket.\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model_dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--sm-model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--test\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TESTING\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "    \r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hosts\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mlist\u001b[39;49;00m, default=json.loads(os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_HOSTS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)))\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--current-host\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CURRENT_HOST\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m parser.parse_known_args()\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\r\n",
      "    args, unknown = _parse_args()\r\n",
      "    train_data, train_labels = _load_data(args.train,\u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    eval_data, eval_labels = _load_data(args.test,\u001b[33m'\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    unique_class = np.unique(train_labels)\r\n",
      "    train_boolean_labels=[label==unique_class \u001b[34mfor\u001b[39;49;00m label \u001b[35min\u001b[39;49;00m train_labels]\r\n",
      "    eval_boolean_labels=[label==unique_class \u001b[34mfor\u001b[39;49;00m label \u001b[35min\u001b[39;49;00m eval_labels]\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(train_boolean_labels)\r\n",
      "    IMG_SIZE=\u001b[34m224\u001b[39;49;00m\r\n",
      "    OUTPUT_SHAPE=\u001b[36mlen\u001b[39;49;00m(unique_class)\r\n",
      "    INPUT_SHAPE=[\u001b[34mNone\u001b[39;49;00m,IMG_SIZE,IMG_SIZE,\u001b[34m3\u001b[39;49;00m]\r\n",
      "    NUM_IMAGES = \u001b[34m200\u001b[39;49;00m\r\n",
      "    BATCH_SIZE=\u001b[34m32\u001b[39;49;00m\r\n",
      "    NUM_EPOCHS=\u001b[34m100\u001b[39;49;00m\r\n",
      "    MODEL_URL=\u001b[33m\"\u001b[39;49;00m\u001b[33mhttps://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "    train_data = create_data_batches(train_data,train_boolean_labels)\r\n",
      "    eval_data = create_data_batches(eval_data,eval_boolean_labels)\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(train_data)\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(eval_data)\r\n",
      "    classifier = create_model(train_data, eval_data,INPUT_SHAPE,OUTPUT_SHAPE,MODEL_URL)\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mDone\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\u001b[33m\"\u001b[39;49;00m\u001b[33mval_accuracy\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,patience=\u001b[34m3\u001b[39;49;00m)\r\n",
      "    classifier.fit(x=train_data,\r\n",
      "            epochs=NUM_EPOCHS,\r\n",
      "            validation_data=eval_data,\r\n",
      "            validation_freq=\u001b[34m1\u001b[39;49;00m,\r\n",
      "            callbacks=[early_stopping])\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mPredictions\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    predictions=classifier.predict(eval_data,verbose=\u001b[34m1\u001b[39;49;00m)\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(predictions)\r\n",
      "    \u001b[34mif\u001b[39;49;00m args.current_host == args.hosts[\u001b[34m0\u001b[39;49;00m]:\r\n",
      "        \u001b[37m#save model to an S3 directory with version number '00000001'\u001b[39;49;00m\r\n",
      "        classifier.save(os.path.join(args.sm_model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33m000000001\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), \u001b[33m'\u001b[39;49;00m\u001b[33mmy_model.h5\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize 'tensorflow_ImageClassifier.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "expired-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type='local'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "exposed-dragon",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributions has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "estimator = TensorFlow(entry_point='launcher.sh',\n",
    "                       dependencies=['tensorflow_ImageClassifier.py'],\n",
    "                       script_mode=True,\n",
    "                       role=role,\n",
    "                       instance_count=1,\n",
    "                       instance_type=instance_type,\n",
    "                       framework_version='2.1.0',\n",
    "                       py_version='py3',\n",
    "                       output_path=model_data_uri,\n",
    "                       base_job_name='tf-ImageClassifier',                       \n",
    "                       distributions={'parameter_server': {'enabled': False}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "appropriate-amount",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating lygcqp76j2-algo-1-kp30b ... \n",
      "Creating lygcqp76j2-algo-1-kp30b ... done\n",
      "Attaching to lygcqp76j2-algo-1-kp30b\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:21,579 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:21,589 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:21,827 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:21,851 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:21,873 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:21,886 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m \n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Training Env:\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m \n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m {\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m     \"additional_framework_parameters\": {\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m         \"sagemaker_parameter_server_enabled\": false\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m     },\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m         \"training\": \"/opt/ml/input/data/training\",\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m         \"testing\": \"/opt/ml/input/data/testing\"\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m     },\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m     \"current_host\": \"algo-1-kp30b\",\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m     \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m         \"algo-1-kp30b\"\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m     ],\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m         \"model_dir\": \"s3://pdfbhawani/ImageClassifier/model/tf-ImageClassifier-2021-03-08-17-28-13-276/model\"\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m     },\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m         \"training\": {\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m         },\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m         \"testing\": {\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m         }\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m     },\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m     \"job_name\": \"tf-ImageClassifier-2021-03-08-17-28-13-276\",\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m     \"master_hostname\": \"algo-1-kp30b\",\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m     \"module_dir\": \"s3://pdfbhawani/tf-ImageClassifier-2021-03-08-17-28-13-276/source/sourcedir.tar.gz\",\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m     \"module_name\": \"launcher.sh\",\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m         \"current_host\": \"algo-1-kp30b\",\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m             \"algo-1-kp30b\"\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m         ]\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m     },\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m     \"user_entry_point\": \"launcher.sh\"\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m }\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m \n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Environment variables:\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m \n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m SM_HOSTS=[\"algo-1-kp30b\"]\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m SM_HPS={\"model_dir\":\"s3://pdfbhawani/ImageClassifier/model/tf-ImageClassifier-2021-03-08-17-28-13-276/model\"}\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m SM_USER_ENTRY_POINT=launcher.sh\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m SM_FRAMEWORK_PARAMS={\"sagemaker_parameter_server_enabled\":false}\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-kp30b\",\"hosts\":[\"algo-1-kp30b\"]}\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m SM_INPUT_DATA_CONFIG={\"testing\":{\"TrainingInputMode\":\"File\"},\"training\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m SM_CHANNELS=[\"testing\",\"training\"]\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m SM_CURRENT_HOST=algo-1-kp30b\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m SM_MODULE_NAME=launcher.sh\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m SM_MODULE_DIR=s3://pdfbhawani/tf-ImageClassifier-2021-03-08-17-28-13-276/source/sourcedir.tar.gz\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_parameter_server_enabled\":false},\"channel_input_dirs\":{\"testing\":\"/opt/ml/input/data/testing\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-kp30b\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1-kp30b\"],\"hyperparameters\":{\"model_dir\":\"s3://pdfbhawani/ImageClassifier/model/tf-ImageClassifier-2021-03-08-17-28-13-276/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"testing\":{\"TrainingInputMode\":\"File\"},\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tf-ImageClassifier-2021-03-08-17-28-13-276\",\"log_level\":20,\"master_hostname\":\"algo-1-kp30b\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://pdfbhawani/tf-ImageClassifier-2021-03-08-17-28-13-276/source/sourcedir.tar.gz\",\"module_name\":\"launcher.sh\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-kp30b\",\"hosts\":[\"algo-1-kp30b\"]},\"user_entry_point\":\"launcher.sh\"}\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m SM_USER_ARGS=[\"--model_dir\",\"s3://pdfbhawani/ImageClassifier/model/tf-ImageClassifier-2021-03-08-17-28-13-276/model\"]\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m SM_CHANNEL_TESTING=/opt/ml/input/data/testing\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m SM_HP_MODEL_DIR=s3://pdfbhawani/ImageClassifier/model/tf-ImageClassifier-2021-03-08-17-28-13-276/model\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m \n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m \n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m /bin/sh -c ./launcher.sh --model_dir s3://pdfbhawani/ImageClassifier/model/tf-ImageClassifier-2021-03-08-17-28-13-276/model\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m \n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Collecting tensorflow-hub\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m   Downloading tensorflow_hub-0.11.0-py2.py3-none-any.whl (107 kB)\n",
      "\u001b[K     |████████████████████████████████| 107 kB 17.9 MB/s eta 0:00:01\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m \u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (1.18.1)\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (3.11.3)\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Requirement already satisfied, skipping upgrade: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-hub) (1.14.0)\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-hub) (46.1.3)\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Installing collected packages: tensorflow-hub\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Successfully installed tensorflow-hub-0.11.0\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m \u001b[33mWARNING: You are using pip version 20.0.2; however, version 21.0.1 is available.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Collecting ipython\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m   Downloading ipython-7.16.1-py3-none-any.whl (785 kB)\n",
      "\u001b[K     |████████████████████████████████| 785 kB 18.1 MB/s eta 0:00:01\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m \u001b[?25hCollecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m   Downloading prompt_toolkit-3.0.16-py3-none-any.whl (366 kB)\n",
      "\u001b[K     |████████████████████████████████| 366 kB 41.3 MB/s eta 0:00:01\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m \u001b[?25hCollecting backcall\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m   Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Collecting traitlets>=4.2\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m   Downloading traitlets-4.3.3-py2.py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 6.3 MB/s  eta 0:00:01\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m \u001b[?25hCollecting pexpect; sys_platform != \"win32\"\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m   Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
      "\u001b[K     |████████████████████████████████| 59 kB 9.1 MB/s  eta 0:00:01\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m \u001b[?25hCollecting decorator\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m   Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Collecting jedi>=0.10\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m   Downloading jedi-0.18.0-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 50.1 MB/s eta 0:00:01\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m \u001b[?25hCollecting pickleshare\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m   Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Collecting pygments\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m   Downloading Pygments-2.8.1-py3-none-any.whl (983 kB)\n",
      "\u001b[K     |████████████████████████████████| 983 kB 66.3 MB/s eta 0:00:01\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m \u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython) (46.1.3)\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Collecting wcwidth\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m   Downloading wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Collecting ipython-genutils\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m   Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython) (1.14.0)\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Collecting ptyprocess>=0.5\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m   Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Collecting parso<0.9.0,>=0.8.0\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m   Downloading parso-0.8.1-py2.py3-none-any.whl (93 kB)\n",
      "\u001b[K     |████████████████████████████████| 93 kB 2.8 MB/s  eta 0:00:01\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m \u001b[?25hInstalling collected packages: wcwidth, prompt-toolkit, backcall, decorator, ipython-genutils, traitlets, ptyprocess, pexpect, parso, jedi, pickleshare, pygments, ipython\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Successfully installed backcall-0.2.0 decorator-4.4.2 ipython-7.16.1 ipython-genutils-0.2.0 jedi-0.18.0 parso-0.8.1 pexpect-4.8.0 pickleshare-0.7.5 prompt-toolkit-3.0.16 ptyprocess-0.7.0 pygments-2.8.1 traitlets-4.3.3 wcwidth-0.2.5\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m \u001b[33mWARNING: You are using pip version 20.0.2; however, version 21.0.1 is available.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m CSV Files count:\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m <generator object list_files.<locals>.<genexpr> at 0x7f48cd677f10>\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Input Files count:1\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m DF Count:\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m ID       10\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Class    10\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m dtype: int64\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m ['/opt/ml/input/data/training/CHNCXR_0001_0.jpg', '/opt/ml/input/data/training/CHNCXR_0002_0.jpg', '/opt/ml/input/data/training/CHNCXR_0003_0.jpg', '/opt/ml/input/data/training/CHNCXR_0004_0.jpg', '/opt/ml/input/data/training/CHNCXR_0005_0.jpg', '/opt/ml/input/data/training/p (784).jpg', '/opt/ml/input/data/training/p (785).jpg', '/opt/ml/input/data/training/p (786).jpg', '/opt/ml/input/data/training/p (787).jpg', '/opt/ml/input/data/training/p (788).jpg']\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m CSV Files count:\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m <generator object list_files.<locals>.<genexpr> at 0x7f48cd677fc0>\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Input Files count:1\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m DF Count:\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m ID       6\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Class    6\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m dtype: int64\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m ['/opt/ml/input/data/testing/CHNCXR_0025_0.jpg', '/opt/ml/input/data/testing/CHNCXR_0036_0.jpg', '/opt/ml/input/data/testing/CHNCXR_0037_0.jpg', '/opt/ml/input/data/testing/image_set4_74.jpg', '/opt/ml/input/data/testing/image_set4_8.jpg', '/opt/ml/input/data/testing/image_set4_9.jpg']\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m [array([False,  True]), array([False,  True]), array([False,  True]), array([False,  True]), array([False,  True]), array([ True, False]), array([ True, False]), array([ True, False]), array([ True, False]), array([ True, False])]\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Creating Training Data Batches...\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Creating Training Data Batches...\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m <BatchDataset shapes: ((None, 224, 224, 3), (None, 2)), types: (tf.float32, tf.bool)>\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m <BatchDataset shapes: ((None, 224, 224, 3), (None, 2)), types: (tf.float32, tf.bool)>\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Building model with : https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m [None, 224, 224, 3]\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Done\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Train for 1 steps, validate for 1 steps\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Epoch 1/100\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.567405: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 652 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.567479: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 486 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.567570: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 541 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.567586: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 509 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.567609: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 641 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.567621: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 619 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.567634: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 597 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.567759: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 114 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.567778: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 82 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.567873: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 172 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.567901: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 193 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.567920: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 127 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.567942: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 149 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.567994: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 138 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.568036: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 92 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.568060: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 103 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.568087: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 161 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.568097: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 183 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.568112: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 204 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.568218: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 475 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.568243: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 587 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.568257: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 565 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.568292: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 498 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.568315: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 608 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.568379: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 429 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.568399: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 630 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.568430: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 530 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.568463: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 576 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.568505: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 520 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.568551: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 552 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.568578: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 451 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.568603: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 374 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.568619: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 351 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.568637: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 464 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.568669: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 440 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.568691: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 419 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.568710: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 363 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.568744: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 397 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.568789: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 239 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.568877: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 340 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.568935: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 408 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.568951: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 385 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.569027: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 316 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.569068: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 294 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.569115: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 329 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.569142: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 262 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.569202: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 228 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.569216: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 284 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.569233: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 305 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.569279: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 250 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.569310: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 273 in the outer inference context.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:38.569363: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 215 in the outer inference context.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.009874: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 172 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.009967: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 149 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.009996: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 183 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010008: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 161 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010037: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 138 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010050: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 114 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010089: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 103 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010124: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 204 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010150: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 127 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010164: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 92 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010173: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 82 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010207: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 641 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010220: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 619 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010232: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 597 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010280: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 565 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010293: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 541 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010306: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 509 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010318: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 486 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010364: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 587 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010394: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 608 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010440: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 530 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010473: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 374 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010488: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 498 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010500: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 475 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010520: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 408 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010545: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 451 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010557: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 429 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010570: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 397 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010619: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 250 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010641: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 464 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010653: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 440 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010664: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 419 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010747: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 363 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010782: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 351 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010837: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 329 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010882: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 305 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010929: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 385 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010942: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 273 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010956: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 340 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.010992: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 239 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.011004: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 316 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.011025: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 262 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.011064: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 294 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.011158: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 284 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.011184: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 228 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.011199: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 215 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.011238: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 652 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.011251: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 576 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.011286: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 552 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.011377: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 630 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.011414: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 520 in the outer inference context.\r\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:39.011547: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 193 in the outer inference context.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 7s 7s/step - loss: 0.3133 - accuracy: 0.9000 - val_loss: 0.3420 - val_accuracy: 0.8333\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Epoch 2/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0965 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.8333\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Epoch 3/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.1146 - val_accuracy: 1.0000\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Epoch 4/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 1.0000\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Epoch 5/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0435 - val_accuracy: 1.0000\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Epoch 6/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0293 - val_accuracy: 1.0000\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Predictions\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m [[9.9542010e-01 4.5799860e-03]\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m  [1.7453372e-02 9.8254669e-01]\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m  [9.9941826e-01 5.8177102e-04]\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m  [1.1776610e-02 9.8822337e-01]\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m  [8.7185723e-01 1.2814276e-01]\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m  [4.0830695e-03 9.9591690e-01]]\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:56.404829: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Instructions for updating:\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m Instructions for updating:\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b |\u001b[0m 2021-03-08 17:28:59,894 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mlygcqp76j2-algo-1-kp30b exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'training':training_data_uri,'testing':testing_data_uri})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "exclusive-idaho",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tf-ImageClassifier-2021-03-08-17-28-13-276'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.latest_training_job.job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "simplified-tamil",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://pdfbhawani/ImageClassifier/model/tf-ImageClassifier-2021-03-08-17-28-13-276/model.tar.gz'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "german-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=sagemaker_session.read_s3_file(bucket_name,training_folder+\"/\"+train_file)\n",
    "#df=pd.read_csv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "obvious-piano",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session.download_data(\"data/\",bucket_name,training_folder+\"/\"+train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sagemaker_session.download_data(\"data/\",bucket_name,testing_folder+\"/\"+test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "great-infrastructure",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/\"+train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cellular-square",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHNCXR_0001_0</td>\n",
       "      <td>XRay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHNCXR_0002_0</td>\n",
       "      <td>XRay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHNCXR_0003_0</td>\n",
       "      <td>XRay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHNCXR_0004_0</td>\n",
       "      <td>XRay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHNCXR_0005_0</td>\n",
       "      <td>XRay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID Class\n",
       "0  CHNCXR_0001_0  XRay\n",
       "1  CHNCXR_0002_0  XRay\n",
       "2  CHNCXR_0003_0  XRay\n",
       "3  CHNCXR_0004_0  XRay\n",
       "4  CHNCXR_0005_0  XRay"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sacred-commander",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_class = np.unique(df[\"Class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bizarre-reception",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "IMG_SIZE=224\n",
    "BATCH_SIZE=32\n",
    "def process_image(image_path,img_size=IMG_SIZE):\n",
    "  image = tf.io.read_file(image_path)\n",
    "  image = tf.image.decode_jpeg(image,channels=3)\n",
    "  image = tf.image.convert_image_dtype(image,tf.float32)\n",
    "  image=tf.image.resize(image,size=[IMG_SIZE,IMG_SIZE])\n",
    "  return image\n",
    "\n",
    "def get_pred_label(prediction_probabilities):\n",
    "  return unique_class[np.argmax(prediction_probabilities)]\n",
    "\n",
    "def create_data_batches(X,batch_size=BATCH_SIZE):\n",
    "    print(\"Creating Test Data Batches...\")\n",
    "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X)))\n",
    "    data_batch = data.map(process_image).batch(batch_size)\n",
    "    return data_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acting-imaging",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "update_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mh7znhzm69j-algo-1-n42v2 |\u001b[0m 172.18.0.1 - - [08/Mar/2021:17:31:25 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"-\"\r\n",
      "!\u001b[36mh7znhzm69j-algo-1-n42v2 |\u001b[0m 2021/03/08 17:31:25 [info] 15#15: *5 client 172.18.0.1 closed keepalive connection\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/sagemaker/local/image.py\", line 827, in run\n",
      "    _stream_output(self.process)\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/sagemaker/local/image.py\", line 887, in _stream_output\n",
      "    raise RuntimeError(\"Process exited with code: %s\" % exit_code)\n",
      "RuntimeError: Process exited with code: 1\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/sagemaker/local/image.py\", line 832, in run\n",
      "    raise RuntimeError(msg)\n",
      "RuntimeError: Failed to run: ['docker-compose', '-f', '/tmp/tmpv1u6pxdj/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Process exited with code: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type=instance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "quarterly-england",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Test Data Batches...\n",
      "<BatchDataset shapes: (None, 224, 224, 3), types: tf.float32>\n",
      "\u001b[36mdlj9vrj3hz-algo-1-1mnga |\u001b[0m 172.18.0.1 - - [02/Mar/2021:15:59:15 +0000] \"POST /invocations HTTP/1.1\" 400 146 \"-\" \"python-urllib3/1.26.2\"\n"
     ]
    }
   ],
   "source": [
    "custom_path=\"data/\"\n",
    "custom_filenames=[training_data_uri +\"/\"+ fname for fname in os.listdir(custom_path)]\n",
    "custom_data=create_data_batches(custom_filenames)\n",
    "print(custom_data)\n",
    "result = predictor.predict(custom_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "similar-boards",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': \"Failed to process element: 0 key: fruit of 'instances' list. Error: Invalid argument: JSON object: does not have named input: fruit\"}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "covered-trademark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gracefully stopping... (press Ctrl+C again to force)\n"
     ]
    }
   ],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
